{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Upload batch file**\n",
    "Once your input file is prepared, you first need to upload the file to then be able to kick off a batch job. File upload can be done both programmatically or via the Studio. This example uses environment variables in place of the key and endpoint values. If you're unfamiliar with using environment variables with Python refer to one of our quickstarts where the process of setting up the environment variables in explained step-by-step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"file-b4ecf74cd14c40ffb1f0cc5680a5eebc\",\n",
      "  \"bytes\": 1646,\n",
      "  \"created_at\": 1722921938,\n",
      "  \"filename\": \"test2-base64-encoded-image.jsonl\",\n",
      "  \"object\": \"file\",\n",
      "  \"purpose\": \"batch\",\n",
      "  \"status\": \"pending\",\n",
      "  \"status_details\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\".env\")  # make sure to have the .env file in the root directory of the project\n",
    "  \n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "    api_version=\"2024-07-01-preview\",\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    )\n",
    "\n",
    "# Upload a file with a purpose of \"batch\"\n",
    "file = client.files.create(\n",
    "  file=open(\"test2-base64-encoded-image.jsonl\", \"rb\"), \n",
    "  purpose=\"batch\"\n",
    ")\n",
    "\n",
    "print(file.model_dump_json(indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "copy the \"id\" value from the json output from previous step\n",
    "define the variable file_id and assign the value to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id =\"file-b4ecf74cd14c40ffb1f0cc5680a5eebc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Track file upload status**\n",
    "Depending on the size of your upload file it might take some time before it's fully uploaded and processed. To check on your file upload status run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-05 22:26:20.477461 File Id: file-b4ecf74cd14c40ffb1f0cc5680a5eebc, Status: processed\n"
     ]
    }
   ],
   "source": [
    "# Wait until the uploaded file is in processed state\n",
    "import time\n",
    "import datetime \n",
    "file_id = file_id\n",
    "status = \"pending\"\n",
    "while status != \"processed\":\n",
    "    time.sleep(15)\n",
    "    file_response = client.files.retrieve(file_id)\n",
    "    status = file_response.status\n",
    "    print(f\"{datetime.datetime.now()} File Id: {file_id}, Status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Create batch job**\n",
    "Once your file has uploaded successfully by reaching a status of processed you can submit the file for batch processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"batch_2608eba1-99ff-4799-9f67-0c9395793a86\",\n",
      "  \"completion_window\": \"24h\",\n",
      "  \"created_at\": 1722922012,\n",
      "  \"endpoint\": \"/chat/completions\",\n",
      "  \"input_file_id\": \"file-b4ecf74cd14c40ffb1f0cc5680a5eebc\",\n",
      "  \"object\": \"batch\",\n",
      "  \"status\": \"validating\",\n",
      "  \"cancelled_at\": null,\n",
      "  \"cancelling_at\": null,\n",
      "  \"completed_at\": null,\n",
      "  \"error_file_id\": null,\n",
      "  \"errors\": null,\n",
      "  \"expired_at\": null,\n",
      "  \"expires_at\": 1723008412,\n",
      "  \"failed_at\": null,\n",
      "  \"finalizing_at\": null,\n",
      "  \"in_progress_at\": null,\n",
      "  \"metadata\": null,\n",
      "  \"output_file_id\": null,\n",
      "  \"request_counts\": {\n",
      "    \"completed\": 0,\n",
      "    \"failed\": 0,\n",
      "    \"total\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Submit a batch job with the file\n",
    "batch_response = client.batches.create(\n",
    "    input_file_id=file_id,\n",
    "    endpoint=\"/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    ")\n",
    "\n",
    "# Save batch ID for later use\n",
    "batch_id = batch_response.id\n",
    "\n",
    "print(batch_response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "copy the \"id\" value from the json output from previous step\n",
    "define the variable batch_id and assign the value to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_id=\"batch_2608eba1-99ff-4799-9f67-0c9395793a86\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Note**\n",
    "\n",
    "Currently the completion window must be set to 24h. If you set any other value than 24h your job will fail. Jobs taking longer than 24 hours will continue to execute until cancelled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Track batch job progress**\n",
    "Once you have created batch job successfully you can monitor its progress either in the Studio or programatically. When checking batch job progress we recommend waiting at least 60 seconds in between each status call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-05 22:28:38.041504 Batch Id: batch_2608eba1-99ff-4799-9f67-0c9395793a86,  Status: validating\n",
      "2024-08-05 22:29:38.966142 Batch Id: batch_2608eba1-99ff-4799-9f67-0c9395793a86,  Status: in_progress\n",
      "2024-08-05 22:30:39.824192 Batch Id: batch_2608eba1-99ff-4799-9f67-0c9395793a86,  Status: in_progress\n",
      "2024-08-05 22:31:40.373427 Batch Id: batch_2608eba1-99ff-4799-9f67-0c9395793a86,  Status: finalizing\n",
      "2024-08-05 22:32:40.992260 Batch Id: batch_2608eba1-99ff-4799-9f67-0c9395793a86,  Status: finalizing\n",
      "2024-08-05 22:33:41.760701 Batch Id: batch_2608eba1-99ff-4799-9f67-0c9395793a86,  Status: finalizing\n",
      "2024-08-05 22:34:42.353162 Batch Id: batch_2608eba1-99ff-4799-9f67-0c9395793a86,  Status: completed\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime \n",
    "\n",
    "status = \"validating\"\n",
    "while status not in (\"completed\", \"failed\", \"canceled\"):\n",
    "    time.sleep(60)\n",
    "    batch_response = client.batches.retrieve(batch_id)\n",
    "    status = batch_response.status\n",
    "    print(f\"{datetime.datetime.now()} Batch Id: {batch_id},  Status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following status values are possible:\n",
    "| Status       | Description                                                                 |\n",
    "|--------------|-----------------------------------------------------------------------------|\n",
    "| validating   | The input file is being validated before the batch processing can begin.    |\n",
    "| failed       | The input file has failed the validation process.                           |\n",
    "| in_progress  | The input file was successfully validated and the batch is currently running.|\n",
    "| finalizing   | The batch has completed and the results are being prepared.                 |\n",
    "| completed    | The batch has been completed and the results are ready.                     |\n",
    "| expired      | The batch wasn't able to be completed within the 24-hour time window.       |\n",
    "| cancelling   | The batch is being cancelled (This may take up to 10 minutes to go into effect.)|\n",
    "| cancelled    | The batch was cancelled.                                                    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To examine the job status details you can run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"batch_2608eba1-99ff-4799-9f67-0c9395793a86\",\n",
      "  \"completion_window\": \"24h\",\n",
      "  \"created_at\": 1722922012,\n",
      "  \"endpoint\": \"/chat/completions\",\n",
      "  \"input_file_id\": \"file-b4ecf74cd14c40ffb1f0cc5680a5eebc\",\n",
      "  \"object\": \"batch\",\n",
      "  \"status\": \"completed\",\n",
      "  \"cancelled_at\": null,\n",
      "  \"cancelling_at\": null,\n",
      "  \"completed_at\": 1722922455,\n",
      "  \"error_file_id\": \"file-5b6f18c1-ec5b-4fff-aaea-7de86409bee9\",\n",
      "  \"errors\": null,\n",
      "  \"expired_at\": null,\n",
      "  \"expires_at\": 1723008412,\n",
      "  \"failed_at\": null,\n",
      "  \"finalizing_at\": 1722922299,\n",
      "  \"in_progress_at\": 1722922149,\n",
      "  \"metadata\": null,\n",
      "  \"output_file_id\": \"file-85bae9c5-3906-4040-9ad9-29134f36330b\",\n",
      "  \"request_counts\": {\n",
      "    \"completed\": 1,\n",
      "    \"failed\": 0,\n",
      "    \"total\": 1\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(batch_response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that there's both error_file_id and a separate output_file_id. Use the error_file_id to assist in debugging any issues that occur with your batch job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Retrieve batch job output file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"custom_id\": \"new-batch-request-1\",\n",
      "  \"response\": {\n",
      "    \"body\": {\n",
      "      \"choices\": [\n",
      "        {\n",
      "          \"content_filter_results\": {\n",
      "            \"hate\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            },\n",
      "            \"self_harm\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            },\n",
      "            \"sexual\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            },\n",
      "            \"violence\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            }\n",
      "          },\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"index\": 0,\n",
      "          \"logprobs\": null,\n",
      "          \"message\": {\n",
      "            \"content\": \"The picture is an emoji with a yellow face, heart-shaped eyes, and an open smile. The emoji conveys feelings of love, adoration, or being enamored with something.\",\n",
      "            \"role\": \"assistant\"\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"created\": 1722922204,\n",
      "      \"id\": \"chatcmpl-9t73kXoNzy1BsFIcwQwJkBjuICKtL\",\n",
      "      \"model\": \"gpt-4o-2024-05-13\",\n",
      "      \"object\": \"chat.completion\",\n",
      "      \"prompt_filter_results\": [\n",
      "        {\n",
      "          \"prompt_index\": 0,\n",
      "          \"content_filter_result\": {\n",
      "            \"jailbreak\": {\n",
      "              \"filtered\": false,\n",
      "              \"detected\": false\n",
      "            },\n",
      "            \"custom_blocklists\": {\n",
      "              \"filtered\": false,\n",
      "              \"details\": []\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"prompt_index\": 1,\n",
      "          \"content_filter_result\": {\n",
      "            \"sexual\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            },\n",
      "            \"violence\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            },\n",
      "            \"hate\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            },\n",
      "            \"self_harm\": {\n",
      "              \"filtered\": false,\n",
      "              \"severity\": \"safe\"\n",
      "            },\n",
      "            \"custom_blocklists\": {\n",
      "              \"filtered\": false,\n",
      "              \"details\": []\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"system_fingerprint\": \"fp_f5a70d8dc9\",\n",
      "      \"usage\": {\n",
      "        \"completion_tokens\": 36,\n",
      "        \"prompt_tokens\": 231,\n",
      "        \"total_tokens\": 267\n",
      "      }\n",
      "    },\n",
      "    \"request_id\": \"dadefee9-5ed4-4126-b255-5026bca8fa0b\",\n",
      "    \"status_code\": 200\n",
      "  },\n",
      "  \"error\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "response = client.files.content(batch_response.output_file_id)\n",
    "raw_responses = response.text.strip().split('\\n')  \n",
    "\n",
    "for raw_response in raw_responses:  \n",
    "    json_response = json.loads(raw_response)  \n",
    "    formatted_json = json.dumps(json_response, indent=2)  \n",
    "    print(formatted_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Additional batch commands**\n",
    "Cancel batch\n",
    "Cancels an in-progress batch. The batch will be in status cancelling for up to 10 minutes, before changing to cancelled, where it will have partial results (if any) available in the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.batches.cancel(\"batch_abc123\") # set to your batch_id for the job you want to cancel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**List batch**\n",
    "List all batch jobs for a particular Azure OpenAI resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[Batch](data=None, value=[{'cancelled_at': None, 'cancelling_at': None, 'completed_at': 1722922455, 'completion_window': '24h', 'created_at': 1722922012, 'error_file_id': 'file-5b6f18c1-ec5b-4fff-aaea-7de86409bee9', 'expired_at': None, 'expires_at': 1723008412, 'failed_at': None, 'finalizing_at': 1722922299, 'id': 'batch_2608eba1-99ff-4799-9f67-0c9395793a86', 'in_progress_at': 1722922149, 'input_file_id': 'file-b4ecf74cd14c40ffb1f0cc5680a5eebc', 'errors': None, 'metadata': None, 'object': 'batch', 'output_file_id': 'file-85bae9c5-3906-4040-9ad9-29134f36330b', 'request_counts': {'total': 1, 'completed': 1, 'failed': 0}, 'status': 'completed', 'endpoint': '/chat/completions'}, {'cancelled_at': None, 'cancelling_at': None, 'completed_at': None, 'completion_window': '24h', 'created_at': 1722921462, 'error_file_id': None, 'expired_at': None, 'expires_at': 1723007862, 'failed_at': 1722921553, 'finalizing_at': None, 'id': 'batch_e7cfaed2-f882-431a-bd8b-f3fffd87f822', 'in_progress_at': None, 'input_file_id': 'file-df6ccc204e5049b498be4a29e8a35cbd', 'errors': {'data': [{'code': 'model_mismatch', 'message': \"The provided model deployment 'REPLACE-WITH-MODEL-DEPLOYMENT-NAME' does not exist in the AOAI resource.\", 'line': None, 'param': None}, {'code': 'invalid_request', 'message': 'The request is invalid.', 'line': None, 'param': None}], 'object': 'list'}, 'metadata': None, 'object': 'batch', 'output_file_id': None, 'request_counts': {'total': 0, 'completed': 0, 'failed': 0}, 'status': 'failed', 'endpoint': '/chat/completions'}, {'cancelled_at': None, 'cancelling_at': None, 'completed_at': None, 'completion_window': '24h', 'created_at': 1722921385, 'error_file_id': None, 'expired_at': None, 'expires_at': 1723007785, 'failed_at': 1722921479, 'finalizing_at': None, 'id': 'batch_b08dec52-ec60-49af-8f65-338fc409ef9a', 'in_progress_at': None, 'input_file_id': 'file-df6ccc204e5049b498be4a29e8a35cbd', 'errors': {'data': [{'code': 'model_mismatch', 'message': \"The provided model deployment 'REPLACE-WITH-MODEL-DEPLOYMENT-NAME' does not exist in the AOAI resource.\", 'line': None, 'param': None}, {'code': 'invalid_request', 'message': 'The request is invalid.', 'line': None, 'param': None}], 'object': 'list'}, 'metadata': None, 'object': 'batch', 'output_file_id': None, 'request_counts': {'total': 0, 'completed': 0, 'failed': 0}, 'status': 'failed', 'endpoint': '/chat/completions'}, {'cancelled_at': None, 'cancelling_at': None, 'completed_at': None, 'completion_window': '24h', 'created_at': 1722921023, 'error_file_id': None, 'expired_at': None, 'expires_at': 1723007423, 'failed_at': 1722921103, 'finalizing_at': None, 'id': 'batch_fc2e0edc-d496-4532-b393-bffa1a31b74c', 'in_progress_at': None, 'input_file_id': 'file-df6ccc204e5049b498be4a29e8a35cbd', 'errors': {'data': [{'code': 'model_mismatch', 'message': \"The provided model deployment 'REPLACE-WITH-MODEL-DEPLOYMENT-NAME' does not exist in the AOAI resource.\", 'line': None, 'param': None}, {'code': 'invalid_request', 'message': 'The request is invalid.', 'line': None, 'param': None}], 'object': 'list'}, 'metadata': None, 'object': 'batch', 'output_file_id': None, 'request_counts': {'total': 0, 'completed': 0, 'failed': 0}, 'status': 'failed', 'endpoint': '/chat/completions'}, {'cancelled_at': None, 'cancelling_at': None, 'completed_at': None, 'completion_window': '24h', 'created_at': 1722918211, 'error_file_id': None, 'expired_at': None, 'expires_at': 1723004611, 'failed_at': 1722918326, 'finalizing_at': None, 'id': 'batch_01d88697-6faf-4d2d-967d-f3d30e50e806', 'in_progress_at': None, 'input_file_id': 'file-21a2d14907da4008bb20704bb9b72177', 'errors': {'data': [{'code': 'model_mismatch', 'message': \"The provided model deployment 'REPLACE-WITH-MODEL-DEPLOYMENT-NAME' does not exist in the AOAI resource.\", 'line': None, 'param': None}, {'code': 'invalid_request', 'message': 'The request is invalid.', 'line': None, 'param': None}], 'object': 'list'}, 'metadata': None, 'object': 'batch', 'output_file_id': None, 'request_counts': {'total': 0, 'completed': 0, 'failed': 0}, 'status': 'failed', 'endpoint': '/chat/completions'}, {'cancelled_at': None, 'cancelling_at': None, 'completed_at': 1722918552, 'completion_window': '24h', 'created_at': 1722918018, 'error_file_id': 'file-81c7a2a0-8ed6-439c-85a3-83e649277818', 'expired_at': None, 'expires_at': 1723004418, 'failed_at': None, 'finalizing_at': 1722918410, 'id': 'batch_cb49fe1e-0c82-41de-bc11-c689ad5c5e09', 'in_progress_at': 1722918219, 'input_file_id': 'file-63e5c4d6208148e79b8d0946b2399bc7', 'errors': None, 'metadata': None, 'object': 'batch', 'output_file_id': 'file-3d68233f-d565-41c3-9e95-0727008491e5', 'request_counts': {'total': 3, 'completed': 3, 'failed': 0}, 'status': 'completed', 'endpoint': '/chat/completions'}, {'cancelled_at': None, 'cancelling_at': None, 'completed_at': None, 'completion_window': '24h', 'created_at': 1722917742, 'error_file_id': None, 'expired_at': None, 'expires_at': 1723004142, 'failed_at': 1722917830, 'finalizing_at': None, 'id': 'batch_26cf956b-aa06-4210-9684-ea9cac5ea10f', 'in_progress_at': None, 'input_file_id': 'file-1225e88637b14b6bae79d3cbbb912bfc', 'errors': {'data': [{'code': 'model_mismatch', 'message': \"The provided model deployment 'REPLACE-WITH-MODEL-DEPLOYMENT-NAME' does not exist in the AOAI resource.\", 'line': None, 'param': None}, {'code': 'invalid_request', 'message': 'The request is invalid.', 'line': None, 'param': None}], 'object': 'list'}, 'metadata': None, 'object': 'batch', 'output_file_id': None, 'request_counts': {'total': 0, 'completed': 0, 'failed': 0}, 'status': 'failed', 'endpoint': '/chat/completions'}], first_id='batch_2608eba1-99ff-4799-9f67-0c9395793a86', has_more=False, last_id='batch_26cf956b-aa06-4210-9684-ea9cac5ea10f')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.batches.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global batch limits\n",
    "| Limit Name            | Limit Value |\n",
    "|-----------------------|-------------|\n",
    "| Max files per resource| 500         |\n",
    "| Max input file size   | 200 MB      |\n",
    "| Max requests per file | 100,000     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model         | Enterprise agreement | Default | Monthly credit card based subscriptions | MSDN subscriptions | Azure for Students, Free Trials |\n",
    "|---------------|----------------------|---------|-----------------------------------------|--------------------|----------------------------------|\n",
    "| gpt-4o        | 5 B                  | 50 M    | 1.35 M                                  | 90 K               | N/A                              |\n",
    "| gpt-4-turbo   | 300 M                | 40 M    | 1.35 M                                  | 90 K               | N/A                              |\n",
    "| gpt-4         | 150 M                | 5 M     | 200 K                                   | 100 K              | N/A                              |\n",
    "| gpt-35-turbo  | 10 B                 | 100 M   | 5 M                                     | 2 M                | 50 K                             |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
